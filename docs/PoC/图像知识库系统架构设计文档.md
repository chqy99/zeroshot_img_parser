# 图像知识库系统架构设计文档

## 1. 引言

本项目旨在构建一个具备零样本图像识别与高效图像检索能力的桌面端智能代理系统。核心目标是实现对桌面屏幕内容的智能感知与理解，并在此基础上构建可检索的图像知识库，为未来的桌面自动化、智能辅助等应用奠定基础。

本文档旨在通过对现有需求和已完成的技术调研成果进行综合分析，设计系统的整体架构，明确各核心模块的功能、技术选型依据及相互接口，为后续的详细设计和开发提供技术蓝图。

## 2. 系统概述

本系统采用模块化设计理念，核心由桌面Agent模块、零样本图像识别模块、图像检索模块、数据处理与存储模块和图像推理模块组成。系统的高层架构如图1所示：

```mermaid
graph TD
    A[桌面Agent模块] --> B[屏幕快照]
    B --> C{数据处理与存储模块<br>(向量数据库)}
    C -- 检索结果 --> A
    B --> D[零样本图像识别模块]
    D -- 分析结果 --> E[数据处理与存储模块<br>(image_dataclass)]
    E --> C
    A -- 检索结果/分析结果 --> F[图像推理模块]
    F -- 推理结果/指令 --> A
```

*图1：系统高层架构图*

*   桌面Agent模块: 负责捕获桌面屏幕快照，接收用户指令，协调各模块的工作流程，并将最终结果呈现给用户或驱动后续操作。
*   零样本图像识别模块: 集成多种先进的零样本视觉模型，对屏幕截图进行多层次的解析，包括分割、目标检测、OCR、区域描述和分类。
*   图像检索模块: 利用向量数据库和高效索引技术，实现基于内容的图像相似度检索，快速查找知识库中已有的相似场景。
*   数据处理与存储模块: 定义并管理用于存储图像分析结果的结构化数据 (`image_dataclass`)，并负责与向量数据库的交互，实现数据的持久化和检索。
*   图像推理模块: 根据图像识别结果、检索结果以及可能的历史/环境上下文，进行更深层次的语义理解和意图推断。

系统的核心流程是：桌面Agent捕获截图 -> 优先进行图像检索判断是否为已知场景 -> 若为已知，利用数据库信息进行推理；若为未知，触发零样本图像识别模块进行详细分析 -> 将分析结果存储到数据库并进行推理 -> 根据推理结果指导Agent后续行为。

## 3. 核心模块详述

### 3.1 零样本图像识别模块

该模块负责对输入的屏幕截图进行详尽的视觉分析，核心在于利用调研报告中提及的零样本能力先进模型。

*   选型依据: 根据调研报告 (`ZeroShotImageRecognitionAndRetrievalSystemAnalysis.md`, `先进零样本图像识别模型 GroundingDINO BLIP CLIP 技术原理及架构特点.md`)，选择以下模型：
    *   SAM2: 强大的零样本分割能力，适用于将复杂的UI界面分割成独立的区域或控件。 ([`Zero-Shot Segmentation`/SAM2])
    *   GroundingDINO: 支持开放词汇的目标检测，可根据“按钮”、“输入框”、“图标”等文本提示词定位UI元素。 ([`image_analyse`/GroundingDINO])
    *   BLIP/BLIP-2: 优秀的多模态理解能力，用于对分割或检测出的区域生成自然语言描述，捕捉区域的语义信息。 ([`image_analyse`/BLIP/BLIP-2], [`zeroshot_classify`/BLIP-2])
    *   CLIP: 强大的跨模态对齐能力，可实现对图像区域的零样本分类，例如将分割出的区域归类到预定义的UI控件类型。 ([`zeroshot_classify`/CLIP])
    *   PaddleOCR: 针对文档图像和通用场景的OCR工具，用于提取截图中的文字信息，文字是桌面UI的关键组成部分。 ([`image_analyse`/PaddleOCR])

*   主要功能:
    1.  接收屏幕截图图像。
    2.  调用SAM2对图像进行分割，获取可能的感兴趣区域掩码。
    3.  结合GroundingDINO和预设或推理生成的UI元素提示词，进行目标检测，获取UI元素的边界框。
    4.  调用PaddleOCR识别图像中的文本，并将文本及其位置关联。
    5.  对分割或检测出的每个区域，使用BLIP/BLIP-2生成详细文本描述。
    6.  对每个区域，使用CLIP根据可能的类别标签进行零样本分类。
    7.  整合以上所有分析结果（掩码、边界框、OCR文本、描述、分类标签）形成结构化的输出。

*   与其他模块的接口:
    *   接收来自桌面Agent模块的屏幕截图输入。
    *   将整合的分析结果输出给数据处理与存储模块，用于构建`image_dataclass`。
    *   输出的文本描述和分类标签也可供图像推理模块使用。

### 3.2 图像检索模块

该模块负责基于图像的特征向量在知识库中进行高效相似度搜索，是实现“优先检索已知场景”业务逻辑的关键。

*   选型依据: 根据向量数据库和索引技术的调研报告 (`大规模图像向量检索索引技术 HNSW ScaNN LSH 速度准确率内存消耗权衡.md`, `向量数据库对比 Milvus Pinecone FAISS Weaviate Qdrant 数据模型索引能力扩展性及图像向量优化.md`)，需要平衡检索速度、准确率、内存消耗和可扩展性。
    *   索引技术: HNSW (Hierarchical Navigable Small World) 在速度和准确率上表现优异，适合对查询延迟要求严格的大规模数据检索。 ([`大规模图像向量检索索引技术 HNSW ScaNN LSH 速度准确率内存消耗权衡.md`])
    *   特征提取: 可以复用CLIP的图像Encoder生成全局和局部的图像特征向量，其在图像-文本跨模态和零样本能力上的优势也体现在特征表示上。也可以考虑其他深度特征提取方法如ResNet变体等。 ([`深度学习图像特征提取方法 细粒度识别实例检索 新兴模型比较.md`])
    *   相似度度量: 余弦相似度或欧氏距离，取决于所用特征向量的归一化方式和表示空间。CLIP特征通常使用余弦相似度。 ([`大规模图像向量检索索引技术 HNSW ScaNN LSH 速度准确率内存消耗权衡.md`], [`向量数据库对比 Milvus Pinecone FAISS Weaviate Qdrant 数据模型索引能力扩展性及图像向量优化.md`])
    *   向量数据库: 考虑以下开源选项，它们都支持存储向量及关联元数据，并提供高效的ANN索引实现（如HNSW）：
        *   Milvus: 专为大规模向量设计，支持分布式和弹性伸缩，多索引支持，对结构化元数据和多向量检索支持良好。 ([`向量数据库对比 Milvus Pinecone FAISS Weiss Weaviate Qdrant 数据模型索引能力扩展性及图像向量优化.md`])
        *   Weaviate/Qdrant: 原生支持结构化数据的存储和混合检索（向量+元数据），API友好，社区活跃，适合`image_dataclass`这种复杂结构。 ([`向量数据库对比 Milvus Pinecone FAISS Weiss Weaviate Qdrant 数据模型索引能力扩展性及图像向量优化.md`])
        *   FAISS: 高性能的向量检索库，适合作为嵌入式或单节点方案后端，但元数据管理需额外开发。 ([`向量数据库对比 Milvus Pinecone FAISS Weiss Weaviate Qdrant 数据模型索引能力扩展性及图像向量优化.md`])

    *   初步选型倾向: 考虑到需要存储复杂的 `image_dataclass` 结构并支持基于元数据的过滤，Milvus、Weaviate 或 Qdrant 作为独立的向量数据库服务是更优的选择。它们提供了更完善的API和分布式能力，特别是Milvus在超大规模数据处理上的优势，Weaviate/Qdrant在结构化数据和混合检索上的便利性。最终选择需根据实际部署环境、数据规模和团队熟悉度决定。可以先从Milvus或Qdrant开始探索。

*   主要功能:
    1.  从输入的屏幕截图生成全局图像特征向量（例如使用CLIP Image Encoder）。
    2.  在向量数据库中执行基于全局向量的相似度搜索。
    3.  根据相似度阈值返回top-k相似的图像分析结果ID或部分数据 (`image_dataclass`)。
    4.  支持基于元数据的过滤，例如根据窗口标题、应用程序名等过滤检索结果。

*   与向量数据库的交互: 通过数据库提供的SDK或API进行向量的插入、删除和相似度查询。

*   与其他模块的接口:
    *   接收来自桌面Agent模块的屏幕截图输入（用于提取查询向量）。
    *   接收来自数据处理与存储模块的存储请求（将新的`image_dataclass`数据插入数据库）。
    *   将检索到的相似结果信息（如匹配的图像ID、相似度分数、部分元数据）返回给桌面Agent模块和图像推理模块。

### 3.3 桌面Agent模块

该模块是系统的入口和控制中心，负责与用户和桌面环境交互，并协调各子模块工作。

*   核心逻辑:
    1.  屏幕捕获: 监听用户的截图操作或按时自动捕获屏幕快照。
    2.  流程调度: 根据业务逻辑（优先检索已知，后进行零样本识别），调用图像检索模块和零样本图像识别模块。
    3.  结果整合与展示: 接收各模块的输出，将图像分析结果和检索结果进行整合。
    4.  与图像推理模块交互: 将检索结果或分析结果发送给图像推理模块进行深层理解。
    5.  响应用户/执行动作: 根据推理模块的输出，向用户展示信息或通过桌面交互库执行模拟操作。
    6.  知识库更新触发: 在完成零样本识别后，触发数据处理与存储模块将新结果保存到知识库。

*   使用的桌面交互库: 根据调研报告 (`Python桌面环境交互库 屏幕截图 用户输入模拟 窗口控件层次结构 获取及模块化代理应用构建方法.md`)：
    *   截图: mss（高性能跨平台）或 Pillow.ImageGrab（简单易用）。
    *   用户输入模拟: PyAutoGUI（跨平台易用）或 pywinauto（Windows平台更精细的控件操作）。
    *   窗口信息获取: pygetwindow 或 pywinauto。
    *   考虑: 需要结合实际需求和平台选择最合适的库。PyAutoGUI和mss的组合能满足基本的截图和输入模拟需求，pywinauto则在Windows平台提供更强的控件交互能力。

*   与其他模块的接口:
    *   向零样本图像识别模块和图像检索模块发送屏幕截图。
    *   接收图像检索模块返回的检索结果。
    *   接收零样本图像识别模块返回的初步分析结果。
    *   将检索/分析结果发送给图像推理模块并接收推理输出。
    *   调用数据处理与存储模块进行知识库的存储操作。

### 3.4 数据处理与存储模块

该模块负责定义和管理存储图像分析结果的数据结构(`image_dataclass`)，并封装与向量数据库的交互逻辑。

*   `image_dataclass` 的结构定义: 根据需求文档 (`ZeroShotImageRecognitionAndRetrievalSystemAnalysis.md`)，`image_dataclass` 核心为 `ImageAnalysisResult` 类，其结构应包含原始图像信息和子区域信息：

    ```python
    @dataclass
    class ImageInstance:
        image: Image.Image  # PIL Image object (or path/bytes representation)
        size: Tuple[int, int] # (width, height)
        source: str # e.g., "original", "GroundingDINO", "OCR", "SAM2"
        class_name: Optional[str] = None # Classification result (e.g., "button", "text_input")
        description: Optional[str] = None # Text description (from BLIP/BLIP-2)
        mask: Optional[np.ndarray] = None # Segmentation mask (binary or instance mask)
        mask_image: Optional[Image.Image] = None # Image after applying mask
        ocr_text: Optional[str] = None # OCR recognized text

        # Add vector field
        vector: Optional[np.ndarray] = None # Feature vector for retrieval (e.g., CLIP embedding)


    @dataclass
    class ImageAnalysisResult:
        original_image: ImageInstance
        region_instances: List[ImageInstance] # List of analyzed regions/UI elements
        bbox_list: List[Tuple[int, int, int, int]] # Bounding boxes corresponding to region_instances, (x1, y1, x2, y2) relative to original_image
        timestamp: datetime # Timestamp of analysis
        # Add global vector field for the original image
        global_vector: Optional[np.ndarray] = None


    ```
    *   ImageInstance: 用于描述图像的某个部分或整体，包含了图像数据、来源、识别或分类结果、描述、可能的掩码和OCR文本。重要的是增加了 `vector` 字段用于存储该区域或整体的特征向量。
    *   ImageAnalysisResult: 包含了原始图像作为一个 `ImageInstance`，以及作为列表存储的各个已分析子区域/UI元素的 `ImageInstance`。`bbox_list` 存储这些子区域在原始图像中的位置信息。增加了 `global_vector` 字段存储整张原始图像的特征向量。时间戳用于记录分析时间。

*   选择的向量数据库及其选型理由:
    *   根据3.2节的分析，倾向于 Milvus 或 Qdrant。
    *   理由: 它们都支持存储复杂的结构化元数据，允许将 `ImageAnalysisResult` 中的非向量字段（如 `class_name`, `description`, `bbox`, `source`, `timestamp`）与向量一起存储。 Milvus 在大规模数据处理和多模式索引上的优势，Qdrant 在灵活元数据和混合查询上的便利性，使其优于仅提供基本向量存储的库（如FAISS）。最终选择需结合实际测试和项目需求。

*   数据如何存取:
    *   存储: 当桌面Agent模块触发知识库存储请求时，该模块接收完整的 `ImageAnalysisResult` 对象。从 `original_image.vector` (或 `global_vector`) 和 `region_instances` 中的 `vector` 字段提取向量，并将对应的元数据（bbox, class_name, description等）组织好，通过向量数据库SDK/API插入到数据库中。可以设计为一张表存储整体截图信息，另一张表存储区域信息，并建立关联；或者在支持多向量的数据库中，将全局向量和局部向量存储关联在同一实体下。
    *   检索: 接收图像检索模块的检索请求（通常是查询向量）。执行向量相似度搜索，可以根据查询目标选择在全局向量或局部向量索引上搜索。返回匹配结果（包含向量及关联的元数据）。这些元数据可以用于重构或定位原始的`image_dataclass`信息。

*   与其他模块的接口:
    *   接收来自桌面Agent模块的存储请求 (`ImageAnalysisResult`对象)。
    *   接收来自图像检索模块的检索请求（查询向量，过滤条件等），并返回检索结果。
    *   向图像检索模块提供数据库连接和操作接口。

### 3.5 图像推理模块

该模块负责超越字面识别的图像理解，根据图像信息和上下文进行逻辑推断，是系统智能化的关键。

*   如何结合上下文进行推理: 根据调研报告 (`上下文感知图像推理 多模态视觉文本结构化数据融合模型及桌面代理集成方案.md`)，上下文感知是核心。可以采用以下策略：
    1.  多模态融合: 接收零样本图像识别模块提供的视觉信息（边界框、类别、描述、OCR文本）和图像检索模块提供的知识库信息。集成桌面环境上下文（如当前活动窗口标题、应用程序名、剪贴板内容、鼠标光标位置、历史操作序列），形成丰富的输入表示。
    2.  基于大模型的推理: 利用多模态大模型（如BLIP-2或其他更先进的VLM/MLLM，或结合Prompt Engineering的大语言模型+视觉特征）对融合后的信息进行推理。例如，分析文本框旁边的按钮，推断其功能；识别已输入的文本和选中的选项，推断用户当前的意图。
    3.  结构化推理: 如果有结构化的知识（如动作知识库，未来规划），可以结合符号逻辑推理或知识图谱推理，将视觉信息映射到已知的用户界面结构和操作流程。
    4.  迭代推理: 在复杂的场景下，可能需要与桌面Agent交互，通过获取更多信息（如鼠标悬停提示、点击某个元素后的界面变化）进行多步推理。

*   与哪些模块交互:
    *   接收桌面Agent模块传递的当前截图信息、检索结果和桌面环境上下文。
    *   接收零样本图像识别模块提供的详细分析结果。
    *   接收图像检索模块提供的已知场景信息。
    *   将推理结果（如对当前场景的解释、用户意图推断、建议的下一步操作、需要执行的模拟指令）输出给桌面Agent模块。

## 4. 数据流和API接口

```mermaid
graph LR
    A[桌面Agent] -->|屏幕截图| B[零样本图像识别模块]
    A -->|屏幕截图| C[图像检索模块]
    B -->|分析结果(image_dataclass)| D[数据处理与存储模块]
    C -->|查询向量/条件| D
    D -->|检索结果(元数据/ID)| C
    D -->|存储 image_dataclass| D
    C -->|检索结果| A
    B -->|分析结果| E[图像推理模块]
    C -->|检索结果| E
    A -->|桌面上下文/历史| E
    E -->|推理结果/指令| A
    D -->|存储确认/状态| A
```

*图2：系统主要数据流图*

主要API接口设想:

*   桌面Agent -> 零样本图像识别:
    *   `recognize_image(image_bytes: bytes) -> dict`: 输入图像字节，返回包含分割、检测、OCR、描述、分类等结果的字典结构。
*   桌面Agent -> 图像检索模块:
    *   `retrieve_similar_images(query_image_bytes: bytes, threshold: float) -> List[dict]`: 输入查询图像字节和相似度阈值，返回相似度高于阈值的已知场景匹配列表。
*   零样本图像识别模块 -> 数据处理与存储模块:
    *   `store_analysis_result(result: ImageAnalysisResult) -> str`: 输入 `ImageAnalysisResult` 对象，将其存储到向量数据库，返回存储的记录ID。
*   图像检索模块 -> 数据处理与存储模块: （内部调用数据库SDK/API）
    *   `insert_vector(vector: list[float], metadata: dict)`
    *   `search_vector(query_vector: list[float], k: int, filter: dict) -> List[dict]`
*   数据处理与存储模块 -> 图像检索模块:
    *   提供数据库连接实例或查询方法封装。
*   桌面Agent/识别/检索模块 -> 图像推理模块:
    *   `infer_from_context(image_analysis: dict, retrieval_results: List[dict], context: dict) -> dict`: 输入图像分析结果、检索结果、桌面上下文，返回推理结果（如意图、建议操作）。
*   图像推理模块 -> 桌面Agent:
    *   返回包含推理结论和可选行动指令的字典或结构。

## 5. 技术选型总结与理由

| 模块/功能                | 关键技术/工具                                   | 选型理由                                                                                                                                                              | 参考调研文件                                    |
| :----------------------- | :---------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------- |
| 零样本分割           | SAM2                                            | 最新的通用零样本分割模型，无需特定数据集标注即可处理未知目标分割。                                                                                                      | `先进零样本图像识别模型...`                       |
| 开放域目标检测       | GroundingDINO                                   | 支持基于文本描述的目标定位，灵活匹配UI元素。                                                                                                                            | `先进零样本图像识别模型...`                       |
| 图像区域描述         | BLIP/BLIP-2                                     | 优秀的多模态理解和文本生成能力，能描述区域内容语义。BLIP-2效率更优。                                                                                                           | `先进零样本图像识别模型...`                       |
| 零样本区域分类       | CLIP                                            | 强大的图像-文本对齐能力，可对区域进行零样本类别判断。                                                                                                                         | `先进零样本图像识别模型...`                       |
| OCR                  | PaddleOCR                                       | 中文识别能力及通用性较好。                                                                                                                                              | 需求文档提到，通用OCR工具。                         |
| 图像特征提取 (检索)  | CLIP Image Encoder (或其他深度模型)                 | CLIP特征在跨模态任务上表现好，且与分类模块复用。                                                                                                                           | `深度学习图像特征提取方法...`                     |
| 向量索引技术         | HNSW                                            | 在速度和准确率之间提供良好平衡，适合大规模数据和低延迟查询需求。                                                                                                                  | `大规模图像向量检索索引技术...`                     |
| 向量数据库           | Milvus 或 Qdrant (初步倾向)                     | 支持存储向量及复杂结构化元数据 (`image_dataclass`)，提供高效ANN索引和API，可扩展性好。Milvus适合超大规模，Qdrant在元数据支持和API上友好。                                              | `向量数据库对比 Milvus Pinecone FAISS...`         |
| 桌面截图             | mss 或 Pillow.ImageGrab                         | mss高性能适合实时，Pillow.ImageGrab简单易用。根据实际需求选择。                                                                                                                       | `Python桌面环境交互库...`                         |
| 用户输入模拟         | PyAutoGUI 或 pywinauto                          | PyAutoGUI跨平台易用，pywinauto Windows下控件交互能力强。根据目标平台和交互复杂性选择。                                                                                              | `Python桌面环境交互库...`                         |
| 窗口信息获取         | pygetwindow 或 pywinauto                        | pygetwindow简单，pywinauto Windows下对控件树更强大。根据需求深度选择。                                                                                                        | `Python桌面环境交互库...`                         |
| 图像推理             | 多模态大模型 (VLM/MLLM) + 上下文融合逻辑          | 结合视觉信息、文本、结构化数据和桌面上下文，利用VLM/MLLM的推理能力。                                                                                                               | `上下文感知图像推理...`                           |
| Agent模块化设计      | 设计模式 (MVC/Observer/Command) + 异步编程 (asyncio) | 提升代码可维护性、扩展性和响应性。                                                                                                                                      | `Python桌面环境交互库...` (模块化Agent构建建议)     |
| 结构化数据定义       | dataclass (Python)                              | 简洁方便地定义结构化数据，包含类型提示。                                                                                                                                  | 需求文档提到 `image_dataclass`。                   |

## 6. 系统特性

*   可扩展性: 模块化设计方便替换或增加新的识别模型、检索算法或推理逻辑。向量数据库（尤其Milvus/Qdrant）支持水平扩展以应对数据量增长。Agent模块可设计为插件式架构。
*   可维护性: 清晰的模块划分和接口定义降低模块间的耦合，易于独立开发、测试和维护。使用标准库和活跃开源项目。
*   性能目标:
    *   截图与识别: 尽可能降低从截图到初步分析的时间，尤其是在零样本识别路径。大型模型的推理延迟是主要挑战，考虑使用模型压缩、量化、TensorRT等优化技术，或在有GPU的环境下部署。
    *   图像检索: 依托向量数据库的高效索引，实现毫秒到亚秒级的相似度检索响应。
    *   整体响应: 桌面Agent在接收到截图后，应在数秒内完成检索/识别和初步推理，提供结果或执行操作。
*   内存与资源消耗: 深度学习模型尤其是大模型内存占用较高，需要在模型选型和部署时予以考虑。可以采用轻量化模型版本，或要求部署环境具备一定硬件资源（如GPU）。

## 7. 部署考虑

*   初步部署策略:
    *   本地部署: 考虑到桌面Agent的特性，核心模块可以部署在用户本地机器上。这要求本地机器具备一定的计算能力，尤其是GPU（推荐NVIDIA GPU，显存8GB以上更佳）以加速深度学习模型的推理。向量数据库可以部署为单机模式（如FAISS作为嵌入式库，或Milvus/Qdrant单机版），或连接到局域网内的向量数据库服务。
    *   混合部署: 部分计算密集型或需要共享的模型/服务（如大规模向量数据库、复杂的推理模型服务）可以部署在云端或内网服务器上，桌面Agent通过API调用。这种方式可以降低本地机器的资源压力，并方便团队成员共享知识库和模型更新。但是会引入网络延迟和数据隐私顾虑。
*   考虑: 零样本图像识别模块对计算资源（尤其是GPU）需求较高，如果目标用户机器不具备GPU，需要考虑CPU推理性能或采用混合部署方案。向量数据库的选择也需要根据部署方式（单机、局域网、云端）来确定。

本架构设计文档提供了系统的整体框架和关键技术选型。后续将基于此进行详细设计，包括模块内部结构、数据流细节、API接口规范、异常处理机制等，并进行技术预研和原型实现，验证关键技术的有效性和性能。